= Alcor Group Agent Design
Eric Li <sze.li@futurewei.com>, Liguang Xie <lxie@futurewei.com>, Chun-Jen (James) Chung<cchung@futurewei.com>
v0.1, 2021-01-28
:toc: right
:sectnums:
:imagesdir: ../../images

NOTE: This document is under development

== Architecture Overview

image:AGA_overview.png[image,width=880,height=640]

== Requirements

We want to have a design that is:

. Ultra high scale - supports up to a million compute hosts in a region
. Efficient control messaging - no chatty protocol like neutron OVS agent
. Super fast dataplane provisioning for both small and large VPC
. Small ACA on host - low resource, simple, can be ran on smart NIC

== Problems to Solve

Other than meeting the requirements above, there are a list of problems to be solved with this design:

. Neighbor and Security Group scale - address scaling issue especially with remote security group rule
. Duplicate configuration - don't send down redundant configuration when compute node has it already
. Out of Order configuration - detect and resolve out of order configuration in goal state messages
. Alcor Control Agent restart handling - provide an efficient way to restore the configuration

== Alcor Group Agent

Alcor Group Agent is introduced here to meet the ultra high scale requirement for the next generation cloud. A set of nearby compute node (in networking term, like their TOR switch is connected to adjacent physical switchs) will be grouped together to form an cluster managed by a set of AGAs. There could be 10,000 machines serviced by this set of AGAs if it meets the performance requirement.

The set of AGAs will store both the latest full state and potential delta states for a resource belongs to a particular compute node, together with the corresponding version numbers. The version numbers are used for out of order detection and handling discuss later. The database will track whether a resource has been sent down to ACA or not. Since the database will be shared with multiple instances of AGAs, lock is needed when reading/writing to a particular resource belongs to a compute host. It is a small and localized lock therefore it should not impact performance. 

AGA will serve as configuration cache or passthrough proxy for network configurations. For port/router/gateway, AGA will always pass down the configuration because the scale is bounded. For neighbor and security group, a hybrid model will be used based on VPC size. That is to pass down to ACA for small VPC, and don't pass down to ACA for large VPC. 

== Location of AGA

There are two options in where AGA could be implemented.

=== Option 1: Make it part of DPM in region level

[source,shell]
------------------------------------------------------------
   +------------------------+
   | +------------------------+
   | | +------------------------+         +--------------------+
   | | |                    | | |         |                    |
   | | |   DPM with AGA     | | |         |                    |
   | | |   functionality    | | |         |                    |
   | | |                    | | +-------->+      ACA           |
   | | |                    | | |         |                    |
   | | |                    | | |         |                    |
   | | |                    | | |         |                    |
   +------------------------+ | |         +--------------------+
     +------------------------+ +--------+
       +------------------------+        |
                   |                     |
                   |                     |
         +---------v----------+          >---------------------+
         |                    |           |                    |
         |                    |           |                    |
         |    ACA             |           |     ACA            |
         |                    |           |                    |
         |                    |           |                    |
         |                    |           |                    |
         +--------------------+           +--------------------+
------------------------------------------------------------

Since all the network configurations are passed down by DPM placed at the region level, it is possible to integration all the AGA functionalities into DPM and reduce the extra layer and component of AGA. However, since DPM is placed at the region level, the on demand requests from ACA may need to take a few extra hops to DPM which can introduce additional latency for the time critical on demand requests.

=== Option 2: Separate AGA placed in the cluster level 

[source,shell]
------------------------------------------------------------
+------------------------+                +------------------------+
| +------------------------+              | +------------------------+
| | +------------------------+            | | +------------------------+         +--------------------+
| | |                    | | |            | | |                    | | |         |                    |
| | |   DPM              +--------------->+ | |   AGA              | | |         |                    |
| | |                    | | |            | | |                    | | |         |                    |
| | |                    | +------------->+ | |                    | | +-------->+      ACA           |
| | |                    | | |            | | |                    | | |         |                    |
| | |                    | | +----------->+ | |                    | | |         |                    |
| | |                    | | |            | | |                    | | |         |                    |
+------------------------+ | |            +------------------------+ | |         +--------------------+
  +------------------------+ |              +------------------------+ +--------+
    +------------------------+                +------------------------+        |
                                                          |                     |
                                                          |                     |
                                                +---------v----------+          >+--------------------+
                                                |                    |           |                    |
                                                |                    |           |                    |
                                                |    ACA             |           |     ACA            |
                                                |                    |           |                    |
                                                |                    |           |                    |
                                                |                    |           |                    |
                                                +--------------------+           +--------------------+
------------------------------------------------------------

To meet the time critical on demand requests, AGA can be a separate component placed at the cluster level. Since AGA is in close network proximity with its ACA compute nodes, network latency should be lower. This model also partition the database to store only the clustered ACA compute nodes. It will be used when option 1 does not meet the latency requirement for on demand requests.


== Security Group Improvements

Security group handling is one of the biggest challenge for public cloud due to its scaling issue especially with remote SG group assoication in a rule. E.g. we have an ingress rule to allow ingress traffic only from the ports assoicated with a default SG. As ports assoication comes and goes, all the existing ports needs to know the latest set of port IPs assoicated with this default SG with the current openstack neutron solution today.  

One approach to address the SG scale issue is to mark each packet with source port SG ID/label. Instead of knowing all the remote IPs on an ingress SG remote rule on the destination side, we can simply mark all egress packets with its associated SG IDs/labels. On the ingress side, it only needs match the ingress remote rule SG ID/label with the marking in the packet. Note that this will greatly help with the scale and IP updates for the ingress remote rule only, but it is an elegent solution which addresses half of the problem for SG. 

One challenge is the current SG ID is a 16 bytes UUID, and each port can be assoicated with upto 5 SG IDs. With  overhead of NSH header or IP options approach, we are looking at adding close to 100 bytes to each packet ((16 bytesx5=80bytes) + overhead). SG ID labeling can be used to reduce adding so much data per packet. Alcor security group manager can generate SG ID label per VPC (or per tenant) and passes it down together with its SG configuration to ACA. Since there is a limit for how many SGs a tenant can create (e.g. 50 per tenant), 1 byte with 256 values should be big enough for the SG ID label.

== ACA on demand request of configuration

There will be situation when ACA doesn't have the needed configuration for a new packet inflight. When that happens, the packet will be punt to ACA and ACA will request info from AGA.

We can use an existing gRPC interface for the bidirectional streaming connection between ACA and AGA:
    rpc PushNetworkResourceStatesStream (stream GoalState) returns (stream GoalStateStatus)

Input: GoalStateStatus - source port ID or IP, destination IP, VNI, source/destination port, protocol - TCP/UDP/Other(ARP/ICMP) 

AGA Workflow:

. Use VNI to lookup VPC
. If needed, find the source port ID based on IP
.. For destination IP on the same subnet, confirm it is L2 neighbor
.. For destination IP on the different subnet, confirm it is L3 neighbor
.. For destination IP from routing rule or gateway, the configurations should be in ACA already
. If confirm it is L2/L3 neighbor, look up SG rules for source port
.. If traffic is allowed, construct and track the corresponding SG config
... send down neighbor and corresponding constructed SG rule
... Reply OperationStatus = SUCCESS (routable) for the rpc call
.. Reply OperationStatus = FAILURE (not routable) for the rpc call
. May go ahead to send down remaining neighbor and SG config for this active port

== Database Requirements

In order to support the Alcor Group Agent, we have the following database requirements:

. Persistent - old data should always be there and not flushed
. Distributed - multiple instances of AGAs can access it concurrently
. Performance - less than 1 millisecond for needed data (e.g. 1000 request per second, each request has multiple reads on around 10 tables with 100gig of configuration stored in database)

== Schema Update

TBD: goal state

*src/schema/proto3/vpc.proto*
[source,java]
------------------------------------------------------------
enum VpcSize { // *** NEW ***
    DEFAULT = 0;
    SMALL = 1;
    CHANGING_TO_LARGE = 2;  // *** DO WE NEED THIS?
    LARGE = 3;
    CHANGING_TO_SMALL = 4;
}

message VpcConfiguration {  
    uint32 revision_number = 1;

    string request_id = 2;
    string id = 3;
    UpdateType update_type = 4; // DELTA (default) or FULL *** REMOVE THIS? ***
    VpcSize vpc_size = 5; // *** NEW ***
    string project_id = 6;
    string name = 7;
    string cidr = 8;
    uint32 tunnel_id = 9;

    message SubnetId {
        string id = 1;
    }

    repeated SubnetId subnet_ids = 10;

    AuxGateway auxiliary_gateway = 11;
}

message VpcState {
    OperationType operation_type = 1;
    VpcConfiguration configuration = 2;
}
------------------------------------------------------------

== AGA Out of Order Configuration Handling

TBD: work flow

== ACA Restart Handling

TBD: work flow

See issue #540, ACA restart handling is described below:

=== Neutron OVS Agent Behavior

Neutron OVS agent inserts a canary table during startup. In its main rpc_loop, it will always check on the ovs status by querying the canary table. ovs_status will be set of OVS_RESTARTED if the canary table is not found. 

To handle the OVS_RESTARTED situation, it will re-setup the bridges (br-int, br-tun, etc) and default flows. It will also reset the dvr if it is enabled. After that, it will rely on a background syncing to get the latest tunnels (for L2 neighbors) and DVR (for L3 neighbors) configurations.

=== Alcor Group Agent Solution

With Alcor Group Agent acting as configuration cache for each compute host. When ACA has detected the dataplane (e.g. OVS) has been restarted, ACA will send GoalStateOperationStatus to AGA with operation_status = RESTARTED. This signals AGA that a partcular ACA needs its help to bring down all the configurations. 

AGA will use existing algorthm to bring down all the configuration for ports/routers/gateways (small or big VPC), and neighbor + security group configuration according to VPC size.

== Work Flows

image:AGA_workflow.png[image,width=880,height=640]

== Detail Slides

Please find the highlevel powerpoint slides of Alcor Group Agent (AGA) in xref:AGA_design.pptx[Alcor Group Agent]